Data:
  data_root:  /root/autodl-tmp/data/MSCOCO2014
  train_list: /root/autodl-tmp/my_work/BAM/lists/coco/train.txt
  val_list:  /root/autodl-tmp/my_work/BAM/lists/coco/val.txt
  classes: 61


Train:
  # Aug
  train_h: 417
  train_w: 417
  val_size: 417
  scale_min: 0.5  # minimum random scale
  scale_max: 2.0 # maximum random scale
  rotate_min: -10  # minimum random rotate
  rotate_max: 10  # maximum random rotate
  ignore_label: 255
  padding_label: 255
  # Dataset & Mode
  split: 0
  data_set: 'coco'
  use_split_coco: True # True means FWB setting
  # Optimizer
  batch_size: 20 # batch size for training (bs12 for 1GPU)
  base_lr: 2.5e-4
  epochs: 50
  start_epoch: 0
  stop_interval: 75 # stop when the best result is not updated for "stop_interval" epochs
  index_split: -1 # index for determining the params group with 10x learning rate
  power: 0.9 # 0 means no decay
  momentum: 0.9
  weight_decay: 0.0001
  warmup: False
  # Viz & Save & Resume
  print_freq: 10
  save_freq: 5
  resume: best.pth # path to latest checkpoint (default: none, such as epoch_10.pth)  
  # Validate
  evaluate: True
  fix_random_seed_val: True
  batch_size_val: 6
  resized_val: True
  ori_resize: False  # use original label for evaluation
  # Else
  workers: 8  # 8 data loader workers
  manual_seed: 321
  seed_deterministic: False
  zoom_factor: 8  # zoom factor for final prediction during training, be in [1, 2, 4, 8]
  
Method:
  layers: 50

